{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZQ_Gx_rrKju"
   },
   "source": [
    "\n",
    "# **2 Training**\n",
    "\n",
    "Scientific Computing Infrastructure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMZ_BMRnge2X"
   },
   "source": [
    "## 1. Preparations\n",
    "### 1.1 Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZhEfhwXBge2Y"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import sklearn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCfa0JGpElrw",
    "outputId": "e55cefa0-c33f-4465-b082-4f336c99b1e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu124\n",
      "Torchvision version: 0.20.1+cu124\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\\nTorchvision version: {torchvision.__version__}\")\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RTROJOlxwZj"
   },
   "source": [
    "### 1.2 Install segmentation model library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAdkr3mEge2a",
    "outputId": "161926d0-42e6-4917-b724-ae25990f8861"
   },
   "outputs": [],
   "source": [
    "# !pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1xI34Hl2ge2a"
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paG6kc2OyBYP"
   },
   "source": [
    "### 1.3 Set device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA Version: 12.4\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "editable": true,
    "id": "8whgTmUHyEq6",
    "outputId": "82a98f84-3d63-445a-ceaa-9e4268334422",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gpu if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcAz9ti5pv0v"
   },
   "source": [
    "### 1.4 Import data directories and configs-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzzP0bfA2bYI",
    "outputId": "d6523fa4-af4c-4f34-8a13-27e63ede7f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/rf37uqip/MoSE/notebooks/configs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.abspath(\"configs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dUtaateBiyhy"
   },
   "outputs": [],
   "source": [
    "# path to repository folder\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('/home/sc.uni-leipzig.de/rf37uqip/MoSE/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P235wsbEilzy",
    "outputId": "c583bc7d-0eac-4df9-93ea-7e3fa4a2d171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'configs.configs_sc' from '/home/sc.uni-leipzig.de/rf37uqip/MoSE/configs/configs_sc.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import configs.py-file\n",
    "from configs import configs_sc\n",
    "importlib.reload(configs_sc) # reload changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "N_bWdgKqge2a"
   },
   "outputs": [],
   "source": [
    "# input directories: patches and masks\n",
    "patches_dir = configs_sc.DATA_DIR[\"patches\"]\n",
    "masks_dir = configs_sc.DATA_DIR[\"masks\"]\n",
    "\n",
    "# output directories: trained models\n",
    "saved_model_dir = configs_sc.DATA_DIR[\"saved_models\"]\n",
    "\n",
    "# additional directories: class (labels and) codes\n",
    "# labels_dir = configs_sc.DATA_DIR[\"labels\"]\n",
    "codes_dir = configs_sc.DATA_DIR[\"codes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Import and reload scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts.visualization_utils' from '/home/sc.uni-leipzig.de/rf37uqip/MoSE/scripts/visualization_utils.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data_utils.py helper-functions script\n",
    "from scripts import data_utils\n",
    "importlib.reload(data_utils) # reload changes\n",
    "\n",
    "# import model_utils.py helper-functions script\n",
    "from scripts import model_utils\n",
    "importlib.reload(model_utils) # reload changes\n",
    "\n",
    "# import train_utils.py helper-functions script\n",
    "from scripts import train_utils\n",
    "importlib.reload(train_utils) # reload changes\n",
    "\n",
    "# import evaluation_utils.py helper-functions script\n",
    "from scripts import evaluation_utils\n",
    "importlib.reload(evaluation_utils) # reload changes\n",
    "\n",
    "# import visualization_utils.py helper function script\n",
    "from scripts import visualization_utils\n",
    "importlib.reload(visualization_utils) # reload changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4S4MeHQqFVT"
   },
   "source": [
    "### 1.6 Check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrOgQ-ZW0mXv"
   },
   "source": [
    "a. Class codes dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFxyHS__ge2b",
    "outputId": "87a88262-02e8-4073-ecc7-d94d8667f448"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/lscratch/data/codes/label_codes_ohe.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m codes_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(codes_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_codes_ohe.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# path\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# open and load the JSON file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(codes_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m      5\u001b[0m     codes \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# reversed dictionary\u001b[39;00m\n",
      "File \u001b[0;32m/software/jupyterlab/conda/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/lscratch/data/codes/label_codes_ohe.json'"
     ]
    }
   ],
   "source": [
    "codes_path = os.path.join(codes_dir, \"label_codes_ohe.json\") # path\n",
    "\n",
    "# open and load the JSON file\n",
    "with open(codes_path, \"r\") as json_file:\n",
    "    codes = json.load(json_file)\n",
    "\n",
    "# reversed dictionary\n",
    "reversed_codes = {v: k for k, v in codes.items()} # v = value, k = key\n",
    "print(reversed_codes[4])\n",
    "print(reversed_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iSvGi59qbKQ"
   },
   "source": [
    "b. Preprocessed patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISqNiRoew3wM",
    "outputId": "08a3d991-df3d-48c6-bed3-09d3f6015221"
   },
   "outputs": [],
   "source": [
    "# list of all .npy-files (preprocessed patches)\n",
    "################################################################################\n",
    "patches_list = [f for f in os.listdir(patches_dir) if f.endswith('.npy')]\n",
    "patches_list[0:3], len(patches_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "id": "vhu2A-ZWNbev",
    "outputId": "d6090979-0266-40bc-d09b-e2f0b4f30fbb"
   },
   "outputs": [],
   "source": [
    "# Test one preprocessed patch\n",
    "################################################################################\n",
    "\n",
    "##################### choose single patch by section and id\n",
    "SECTION = \"A06\" # -------------------->> ADJUSTABLE\n",
    "TEST_PATCH_ID = 200 # -------------------->> ADJUSTABLE\n",
    "#####################\n",
    "\n",
    "# load the path to the patch\n",
    "test_patch_name = f\"{SECTION}_patch_{TEST_PATCH_ID}.npy\"\n",
    "test_patch_path = patches_dir + f\"/\" + test_patch_name\n",
    "\n",
    "# load npz-file\n",
    "test_patch = np.load(test_patch_path)\n",
    "\n",
    "  # Show characteristics of the patch\n",
    "print(\"Shape of the patches:\", test_patch.shape)\n",
    "print(\"Datatype:\", test_patch.dtype)\n",
    "print(\"Type:\", type(test_patch))\n",
    "print(\"Mean:\", np.mean(test_patch))\n",
    "print(\"Minimum value:\", np.min(test_patch))\n",
    "print(\"Maximum value:\", np.max(test_patch))\n",
    "\n",
    "# import the norm_plot_patch function for normalization and plotting of the test patch\n",
    "visualization_utils.norm_plot_patch(test_patch, test_patch_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qo7ys6dSqfX5"
   },
   "source": [
    "3. Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YXVuxh2x7sY",
    "outputId": "90cedaaa-08b1-4f9a-b214-1dd90d11dac6"
   },
   "outputs": [],
   "source": [
    "# list of all masks\n",
    "################################################################################\n",
    "\n",
    "masks_list = [f for f in os.listdir(masks_dir) if f.endswith('_mask.npy')]  # list of all masks\n",
    "print(masks_list[0:3])\n",
    "len(masks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OC_bi14-8mtP",
    "outputId": "2300f61c-16eb-42de-f9bc-425ed80d89c5"
   },
   "outputs": [],
   "source": [
    "# Test mask\n",
    "################################################################################\n",
    "\n",
    "##################### Choose single mask by section and id\n",
    "SECTION = \"A06\" # -------------------->> ADJUSTABLE\n",
    "TEST_MASK_ID = 200 # -------------------->> ADJUSTABLE\n",
    "#####################\n",
    "\n",
    "# Path to the chosen mask\n",
    "test_mask_name = f\"{SECTION}_patch_{TEST_MASK_ID}_mask.npy\"\n",
    "test_mask_path = masks_dir + f\"/\" + test_mask_name\n",
    "\n",
    "# Load mask\n",
    "test_mask = np.load(test_mask_path)\n",
    "\n",
    "# Show properties of the mask\n",
    "print(\"Shape of the mask:\", test_mask.shape)\n",
    "print(\"Datatype:\", test_mask.dtype)\n",
    "print(\"Type:\", type(test_mask))\n",
    "print(\"Minimum value:\", np.min(test_mask))\n",
    "print(\"Maximum value:\", np.max(test_mask))\n",
    "print(\"Unique values:\", np.unique(test_mask), \"\\n\") # binary mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT-ENCODED\n",
    "print(test_mask_name)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 12))  # 2x3 grid (for 5 classes)\n",
    "axes = axes.flatten()  # easier to iterate through\n",
    "\n",
    "for i in range(test_mask.shape[0]):  # iterate through the classes\n",
    "  axes[i].imshow(test_mask[i], cmap=\"gray\")\n",
    "  axes[i].set_title(f\"Class {i} - - {reversed_codes[i]}\")\n",
    "  axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way of plotting the masks - not in one-hot-encoded, but in class-index-format\n",
    "# CLASS-INDEX-FORMAT\n",
    "\n",
    "# convert into class-index format\n",
    "test_mask_idxformat = np.argmax(test_mask, axis=0)\n",
    "\n",
    "visualization_utils.plot_mask_idxformat(test_mask_idxformat, test_mask_name, reversed_codes, configs_sc.HYPERPARAMETERS[\"custom_colors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToHcZmjUge2c"
   },
   "source": [
    "## 2. Splitting data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Cn8tFMjsYMZ",
    "outputId": "a79a2647-d571-415f-eb36-548c26db3fcb"
   },
   "outputs": [],
   "source": [
    "# extract section and patch_id from masks and patches (utils function)\n",
    "print(data_utils.extract_section_and_id(masks_list[2]))\n",
    "print(data_utils.extract_section_and_id(patches_list[175]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xq6_p1FTQByr",
    "outputId": "50ad6ef1-1f53-4e03-d06f-f6e663350aa9"
   },
   "outputs": [],
   "source": [
    "# group patches by section\n",
    "################################################################################\n",
    "\n",
    "section_patches = {} # empty dictionary\n",
    "for patch in patches_list: # iterate over all preprocessed patches\n",
    "    section, patch_id = data_utils.extract_section_and_id(patch) # extract section and id\n",
    "    section_patches.setdefault(section, []).append((patch)) # creates keys of sections with their patches inside\n",
    "\n",
    "print(section_patches.keys())\n",
    "# print(section_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-DUEfQCQ_DK",
    "outputId": "bee4659e-fe3d-4856-b563-7600e120b28f"
   },
   "outputs": [],
   "source": [
    "# Separate patches in Training and Validation/Test datasets by sections\n",
    "################################################################################\n",
    "\n",
    "# empty lists for patches\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for section, files in section_patches.items(): # iterates through the dictionary of sections\n",
    "    if section in configs_sc.HYPERPARAMETERS[\"train_sections\"]: # if the section is a training section\n",
    "        train_data.extend(files) # if yes, the patches are added to the training data\n",
    "    elif section in configs_sc.HYPERPARAMETERS[\"test_sections\"]:\n",
    "        test_data.extend(files)\n",
    "\n",
    "print(f\"Training Patches: {len(train_data)}\")\n",
    "print(f\"Test Patches: {len(test_data)}\")\n",
    "print(f\"Testdata-Ratio: {100*(len(test_data)/len(train_data))}\")\n",
    "print(f\"Traindata-Ratio: {100 - 100*(len(test_data)/len(train_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kwq3e4W-Hj_",
    "outputId": "2eccdb64-d27e-4dbd-eae7-39ac0f93f15c"
   },
   "outputs": [],
   "source": [
    "# Show random patch name in training data\n",
    "print(train_data[8])\n",
    "\n",
    "# test if this random patch has a corresponding mask\n",
    "data_utils.has_mask(train_data[8], masks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgAZUMH5Am0t",
    "outputId": "5b7a5f37-b5a4-481b-8358-63e87bac7540"
   },
   "outputs": [],
   "source": [
    "# Separate training and test patches \n",
    "################################################################################\n",
    "\n",
    "train_data = [f for f in train_data if data_utils.has_mask(f, masks_dir)]\n",
    "test_data = [f for f in test_data if data_utils.has_mask(f, masks_dir)]\n",
    "\n",
    "print(f\"Training data- Number of patches: {len(train_data)}\")\n",
    "print(f\"Test data - Number of patches: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx6ETto8pj1t"
   },
   "source": [
    "## 3. Data augmentation, Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NQ9HI9vrest"
   },
   "source": [
    "### 3.1 Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Define training transformations with augmentation using Albumentations\n",
    "train_transforms = A.Compose([\n",
    "    \n",
    "    # horizontal flip with a probability of 0.5\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # vertical flip \n",
    "    A.VerticalFlip(p=0.5), \n",
    "    # randomly rotate the image by 90 degrees \n",
    "    A.RandomRotate90(p=0.5), \n",
    "    # random adjustments to brightness, contrast, saturation, and hue\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5), \n",
    "    # affine transformation:\n",
    "    A.Affine(rotate=(-90, 90), translate_percent=(-0.1, 0.1), scale=(0.9, 1.1), p=0.5),\n",
    "    # - rotate: randomly rotate within the range (-90, 90) degrees\n",
    "    # - translate_percent: randomly translate by up to Â±10% of image dimensions\n",
    "    # - scale: randomly scale the image between 0.9 and 1.1 times its original size\n",
    "    # normalize the image using ImageNet statistics\n",
    "    # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "    # covert to Tensors\n",
    "    ToTensorV2() \n",
    "], additional_targets={'mask': 'mask'}) # ensures the same transformation is applied to the mask\n",
    "\n",
    "\n",
    "# Define test transformations without augmentation (only normalization and conversion to tensor)\n",
    "test_transforms = A.Compose([\n",
    "    # normalize the image using ImageNet statistics\n",
    "    # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "    # covert to Tensors\n",
    "    ToTensorV2() \n",
    "], additional_targets={'mask': 'mask'}) # ensures the same transformation is applied to the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Datasets and check properties\n",
    "################################################################################\n",
    "\n",
    "# Train dataset\n",
    "train_dataset = data_utils.PatchDatasetCplx(train_data, patches_dir, masks_dir, transform = train_transforms)\n",
    "\n",
    "# check properties of the train dataset:\n",
    "print(\"Train dataset:\\n\")\n",
    "print(\"Type of dataset:\", type(train_dataset))\n",
    "print(\"Number of patches:\", len(train_dataset))\n",
    "print(\"Random patch:\", train_dataset[0][0])\n",
    "print(\"Patch shape:\", train_dataset[0][1].shape)\n",
    "print(\"Mask shape:\", train_dataset[0][2].shape, \"\\n\")\n",
    "\n",
    "# Test datasets\n",
    "test_dataset = data_utils.PatchDatasetCplx(test_data, patches_dir, masks_dir, transform = test_transforms) \n",
    "\n",
    "# check properties of the test dataset:\n",
    "print(\"Test dataset:\\n\")\n",
    "print(\"Type of dataset:\", type(test_dataset))\n",
    "print(\"Number of patches:\", len(test_dataset))\n",
    "print(\"Random patch:\", test_dataset[0][0])\n",
    "print(\"Patch shape:\", test_dataset[0][1].shape)\n",
    "print(\"Mask shape:\", test_dataset[0][2].shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwUUK2_WwllN",
    "outputId": "1083b67a-6459-4f97-d1e3-7c0a9d075b47"
   },
   "outputs": [],
   "source": [
    "# # Apply Datasets and check properties\n",
    "# ################################################################################\n",
    "\n",
    "# # Train dataset\n",
    "# train_dataset = data_utils.PatchDatasetSimple(train_data, patches_dir, masks_dir)\n",
    "\n",
    "# # check properties of the train dataset:\n",
    "# print(\"Train dataset:\\n\")\n",
    "# print(\"Type of dataset:\", type(train_dataset))\n",
    "# print(\"Number of patches:\", len(train_dataset))\n",
    "# print(\"Random patch:\", train_dataset[0][0])\n",
    "# print(\"Patch shape:\", train_dataset[0][1].shape)\n",
    "# print(\"Mask shape:\", train_dataset[0][2].shape, \"\\n\")\n",
    "\n",
    "# # Test datasets\n",
    "# test_dataset = data_utils.PatchDatasetSimple(test_data, patches_dir, masks_dir) \n",
    "\n",
    "# # check properties of the test dataset:\n",
    "# print(\"Test dataset:\\n\")\n",
    "# print(\"Type of dataset:\", type(test_dataset))\n",
    "# print(\"Number of patches:\", len(test_dataset))\n",
    "# print(\"Random patch:\", test_dataset[0][0])\n",
    "# print(\"Patch shape:\", test_dataset[0][1].shape)\n",
    "# print(\"Mask shape:\", test_dataset[0][2].shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcnjTDxcrlZq"
   },
   "source": [
    "### 3.3 DataLoader\n",
    "\n",
    "Right now our data is in the form of Pytorch Datasets (see above). The next step is to prepare it with a [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) or simply `DataLoader`.\n",
    "\n",
    "The `DataLoader`\n",
    "- helps load data into a model.\n",
    "- for training and for inference.\n",
    "- **turns a large `Dataset` into a Python iterable** of smaller chunks. These smaller chunks are called **batches** or **mini-batches** and can be set by the `batch_size` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Ld2FgTWOfrZ",
    "outputId": "149f5117-1cb7-4d75-fb14-36a3b84684e8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = configs_sc.HYPERPARAMETERS[\"batch_size\"]\n",
    "\n",
    "# Train DataLoader\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "print(\"Dataloader:\", train_loader)\n",
    "\n",
    "# Test DataLoader\n",
    "test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Check dataloader\n",
    "print(f\"Training Batches: {len(train_loader)}\", f\"= up to {len(train_loader)*BATCH_SIZE} patches\")\n",
    "print(f\"Test Batches: {len(test_loader)}\", f\"= up to {len(test_loader)*BATCH_SIZE} patches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYQ0-CIy85QW"
   },
   "source": [
    "### 3.4 Data exploration and class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGfD8AZHPej2"
   },
   "outputs": [],
   "source": [
    "# # Explore one batch of data in train_loader\n",
    "# for batch_idx, (names, images, masks) in enumerate(train_loader):\n",
    "#     print(f\"Batch {batch_idx + 1}:\", \"\\n------------\\n------------\")\n",
    "#     print(f\"Names - first patch name of the batch: {names[0]}\", \"\\n------------\")\n",
    "#     print(f\"Image type: {type(images)}\")\n",
    "#     print(f\"Images shape: {images.shape}\")  # Should be [batch_size, channels, height, width]\n",
    "#     print(f\"Image excerpt of the first patch: {images[0,:,:4,:4]}\")\n",
    "#     print(f\"Images dtype: {images.dtype}\", \"\\n------------\")\n",
    "#     print(f\"Masks shape: {masks.shape}\")    # Should be [batch_size, channels, height, width]\n",
    "#     print(f\"Mask excerpt of the mask of the fourth patch: {masks[0,:,:2,:2]}\")\n",
    "#     print(f\"Masks dtype: {masks.dtype}\")\n",
    "#     break # break after first batch (batch 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TRAIN LOADER\n",
    "# # Show pixel distribution per class in train_loader\n",
    "# pixel_distribution_train = data_utils.pixel_distribution_dataloader(\n",
    "#     data_loader=train_loader,\n",
    "#     num_classes= configs_sc.HYPERPARAMETERS[\"num_classes\"],\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# # Visualize results\n",
    "# plt.bar(pixel_distribution_train.keys(), pixel_distribution_train.values())\n",
    "# plt.xlabel(\"Class\")\n",
    "# plt.ylabel(\"Percentage of Pixels (%)\")\n",
    "# plt.title(\"Pixel Distribution Across Classes (Train Dataset)\")\n",
    "# plt.xticks()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST LOADER\n",
    "# # Show pixel distribution per class in test_loader\n",
    "# pixel_distribution_test = data_utils.pixel_distribution_dataloader(\n",
    "#     data_loader=test_loader,\n",
    "#     num_classes= configs_sc.HYPERPARAMETERS[\"num_classes\"],\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# # Visualize results\n",
    "# plt.bar(pixel_distribution_test.keys(), pixel_distribution_test.values())\n",
    "# plt.xlabel(\"Class\")\n",
    "# plt.ylabel(\"Percentage of Pixels (%)\")\n",
    "# plt.title(\"Pixel Distribution Across Classes (Test Dataset)\")\n",
    "# plt.xticks()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_dist_train = torch.tensor(list(pixel_distribution_train.values()), dtype=torch.float32, device=device)\n",
    "pixel_dist_train = torch.tensor([98.5564,  1.4437], dtype=torch.float32, device=device)\n",
    "print(\"Pixel distribution in train dataset:\", pixel_dist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaogTcsjOuqW",
    "outputId": "9173cef4-1817-4dcb-e486-3e65dbb3899c"
   },
   "outputs": [],
   "source": [
    "# calculate the weights to outweigh the class imbalances\n",
    "class_weights = 1/ (pixel_dist_train/100)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "normalized_weights = class_weights / class_weights.sum()\n",
    "print(\"Normalized weights:\", normalized_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oajlTVrZRS5V"
   },
   "source": [
    "To take into account the class imbalances in this dataset, we adjust the weight parameters in the CrossEntropyLoss function accordingly. Based on the pixel distribution, the weights can be set as follows:\n",
    "\n",
    "| Class | Average pixel distribution (%) | Normalized Weight |\n",
    "| ----- | ----- | ----- |\n",
    "| 0 | 98.5564 | 0.0144 |\n",
    "| 1 | 1.4437   | 0.9856 |\n",
    "\n",
    "\n",
    "(\n",
    "| 2 | 0.1185 | 0.5546 |\n",
    "| 3 | 0.2076 | 0.3164 |\n",
    "| 4 | 0.7930 | 0.0829 |\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guMstWKFge2b"
   },
   "source": [
    "## 4. Segmentation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4x0laGVxuH2"
   },
   "source": [
    "Unet_ is a fully convolution neural network for image semantic segmentation. Consist of encoder and decoder parts connected with skip connections. Encoder extract features of different spatial resolution (skip connections) which are used by decoder to define accurate segmentation mask. Use concatenation for fusing decoder blocks with skip connections.\n",
    "\n",
    "URL: https://smp.readthedocs.io/en/latest/models.html#unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcaVNUIryA07"
   },
   "source": [
    "``class segmentation_models_pytorch.Unet(encoder_name='resnet34', encoder_depth=5, encoder_weights='imagenet', decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=1, activation=None, aux_params=None, **kwargs)``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_rZ-6Smge2b"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# model_0 = smp.Unet(   # -------------------->> ADJUSTABLE\n",
    "#     encoder_name=\"resnet18\", # choose encoder, e.g. mobilenet_v2 or       efficientnet-b7\n",
    "#     encoder_weights=\"imagenet\", # use `imagenet` pre-trained weights for encoder initialization\n",
    "#     in_channels=3, # model input channels (3 for RGB)\n",
    "#     classes=len(codes), # model output channels (number of classes)\n",
    "# ).to(device)\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPeEhgzBAf2N"
   },
   "outputs": [],
   "source": [
    "model = model_utils.model_0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w921PAA7J33"
   },
   "outputs": [],
   "source": [
    "# show model costruction\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGefGR7L7f2-"
   },
   "outputs": [],
   "source": [
    "# show (hidden) layers of the model\n",
    "# model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFfXf9FrBAPW"
   },
   "outputs": [],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC2n49Xgge2c"
   },
   "source": [
    "### 4.1 Setup loss, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVygUxz0ghHO"
   },
   "source": [
    "Setup loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTW5PIDkZlJa"
   },
   "outputs": [],
   "source": [
    "# Setup loss function\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.CrossEntropyLoss(weight = normalized_weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmU_qQrtu5SE"
   },
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "# optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), configs_sc.HYPERPARAMETERS[\"learning_rate\"], betas=(0.9, 0.999))\n",
    "\n",
    "# AdamW = Adam with weight decay\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=configs_sc.HYPERPARAMETERS[\"learning_rate\"],  # learning rate\n",
    "    weight_decay=1e-4  # regularisation\n",
    ")\n",
    "\n",
    "# # Scheduler for learning rate decay (optional)\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # learning rate will be reduced every 10 epochs with factor 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr0lOb7Bg9ki"
   },
   "source": [
    "Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hg0D-rd6AnmZ"
   },
   "outputs": [],
   "source": [
    "accuracy_fn = evaluation_utils.oa_accuracy_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsFV2qXU-a-2"
   },
   "source": [
    "### 4.2 Creating a training loop and training a model on batches of data\n",
    "\n",
    "1. Loop through epochs.\n",
    "2. Loop through training batches, perform training steps, calculate the train loss *per batch*.\n",
    "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*.\n",
    "4. Print out what's happening.\n",
    "5. Time it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0babcbba5b3d4151b15c00838a29ac33",
      "8b4bdb6ff45b430593277fa37e4d35ff",
      "8e37aa7beecc4533a0cfb52ff1c88fc6",
      "aaf88acb439641638112b4703c935672",
      "abde49efc7d0493ba9aea25ca4c60050",
      "ccda5c70ea8e4545a6ad9dbec748c27b",
      "9bbb8694f72242588ea53dbe318c6ce7",
      "3ff2f7585bec48a485704ecc8f2be347",
      "29589acaa6bc405cb6e040dc3f7ea2fa",
      "76cd84f3409843ee87769dc0aa3b52ed",
      "c85b6558ac9140a9895b4d97f2285472"
     ]
    },
    "id": "DfJTx00L9G68",
    "outputId": "d2d913e2-d8b6-4741-bd2f-b5f505f36d89"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "torch.manual_seed(configs_sc.HYPERPARAMETERS[\"seed\"])\n",
    "torch.cuda.manual_seed(configs_sc.HYPERPARAMETERS[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"Learning rate:\", configs_sc.HYPERPARAMETERS[\"learning_rate\"])\n",
    "print(\"Number of epochs:\", configs_sc.HYPERPARAMETERS[\"epochs\"])\n",
    "\n",
    "# measure time with timing function\n",
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "\n",
    "# empty lists for storing of evaluation metrics\n",
    "train_loss_progress = []\n",
    "test_loss_progress = []\n",
    "train_class_wise_losses = []\n",
    "test_class_wise_losses = []\n",
    "\n",
    "# epoch loop\n",
    "for epoch in tqdm(range(configs_sc.HYPERPARAMETERS[\"epochs\"])):\n",
    "    print(f\"Epoch: {epoch}\\n---------\") # print current epoch\n",
    "\n",
    "    train_loss_epoch, train_class_wise_loss = train_utils.train_step(\n",
    "        model=model,\n",
    "        num_classes=configs_sc.HYPERPARAMETERS[\"num_classes\"],\n",
    "        data_loader=train_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    train_loss_progress.append({\"epoch\": epoch + 1, \"train loss\": train_loss_epoch})\n",
    "    train_class_wise_losses.append(train_class_wise_loss.cpu().numpy())  # change to numpy for easier plotting\n",
    "\n",
    "    test_loss_epoch, test_class_wise_loss = train_utils.test_step(\n",
    "        model=model,\n",
    "        num_classes=configs_sc.HYPERPARAMETERS[\"num_classes\"],\n",
    "        data_loader=test_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    test_loss_progress.append({\"epoch\": epoch + 1, \"test loss\": test_loss_epoch})\n",
    "    test_class_wise_losses.append(test_class_wise_loss.cpu().numpy())\n",
    "\n",
    "\n",
    "    # Clear output and update plot\n",
    "    epochs = [entry[\"epoch\"] for entry in train_loss_progress]\n",
    "    train_losses = [entry[\"train loss\"] for entry in train_loss_progress]\n",
    "    test_losses = [entry[\"test loss\"].cpu().item() for entry in test_loss_progress]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, test_losses, label=\"Test Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train and Test Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "end = timer()\n",
    "train_utils.print_train_time(start, end, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUALIZE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train class-wise loss of a specific epoch\n",
    "# ADJUSTABLE!\n",
    "try_epoch = 2\n",
    "visualization_utils.plot_classwise_loss(try_epoch, train_class_wise_losses, configs_sc.HYPERPARAMETERS[\"num_classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test class-wise loss of a specific epoch\n",
    "visualization_utils.plot_classwise_loss(try_epoch, test_class_wise_losses, configs_sc.HYPERPARAMETERS[\"num_classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train loss curves per class\n",
    "\n",
    "# Create a list of epoch numbers based on the number of entries in train_class_wise_losses\n",
    "epochs = list(range(1, len(train_class_wise_losses) + 1))\n",
    "\n",
    "# Extract the loss for class 0 and class 1 for each epoch.\n",
    "# Here, we assume that each entry in train_class_wise_losses is a tuple or array like [loss_class0, loss_class1, ...].\n",
    "class0_losses = [losses[0] for losses in train_class_wise_losses]\n",
    "class1_losses = [losses[1] for losses in train_class_wise_losses]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, class0_losses, marker='o', linestyle='-', label=\"Train Loss for Class 0 (Background)\")\n",
    "plt.plot(epochs, class1_losses, marker='o', linestyle='-', label=\"Train Loss for Class 1 (Totholz)\")\n",
    "plt.xlabel(\"Epoch\")                          # Set the x-axis label\n",
    "plt.ylabel(\"Loss\")                           # Set the y-axis label\n",
    "plt.title(\"Training Loss per Epoch per Class\")  # Set the plot title\n",
    "plt.legend()                                 # Display the legend\n",
    "plt.grid(True)                               # Enable grid for better readability\n",
    "plt.show()                                   # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the test loss curves per class\n",
    "\n",
    "# Create a list of epoch numbers based on the number of entries in train_class_wise_losses\n",
    "epochs = list(range(1, len(test_class_wise_losses) + 1))\n",
    "\n",
    "# Extract the loss for class 0 and class 1 for each epoch.\n",
    "# Here, we assume that each entry in train_class_wise_losses is a tuple or array like [loss_class0, loss_class1, ...].\n",
    "class0_losses = [losses[0] for losses in test_class_wise_losses]\n",
    "class1_losses = [losses[1] for losses in test_class_wise_losses]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, class0_losses, marker='o', linestyle='-', label=\"Test Loss for Class 0 (Background)\")\n",
    "plt.plot(epochs, class1_losses, marker='o', linestyle='-', label=\"Test Loss for Class 1 (Totholz)\")\n",
    "plt.xlabel(\"Epoch\")                          # Set the x-axis label\n",
    "plt.ylabel(\"Loss\")                           # Set the y-axis label\n",
    "plt.title(\"Test Loss per Epoch per Class\")  # Set the plot title\n",
    "plt.legend()                                 # Display the legend\n",
    "plt.grid(True)                               # Enable grid for better readability\n",
    "plt.show()                                   # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmtgGeVpVOCv"
   },
   "source": [
    "## 5. Save and load trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create individual name of the trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create INDIVIDUAL model name and add to corresponding path\n",
    "\n",
    "# counter for model version\n",
    "counter = 1\n",
    "\n",
    "# function for generating initial model name\n",
    "def generate_model_name(base_name, learning_rate, epochs, counter):\n",
    "    return f\"{base_name}_{learning_rate}_{epochs}_{counter}.pth\"\n",
    "\n",
    "base_name = \"unet_model_2classes_dataaugmentation_nonormalization\"\n",
    "\n",
    "# generate initial name and path\n",
    "MODEL_NAME = generate_model_name(base_name, configs_sc.HYPERPARAMETERS[\"learning_rate\"], configs_sc.HYPERPARAMETERS[\"epochs\"], counter)\n",
    "save_model_path = os.path.join(saved_model_dir, MODEL_NAME)\n",
    "\n",
    "# check if there is already a model saved with the same name -> if so: increase the counter\n",
    "while os.path.exists(save_model_path):\n",
    "    print(f\"Warning: File with name {MODEL_NAME} already exists. Increase the counter...\")\n",
    "    counter += 1\n",
    "    MODEL_NAME = generate_model_name(base_name, configs_sc.HYPERPARAMETERS[\"learning_rate\"], configs_sc.HYPERPARAMETERS[\"epochs\"], counter)\n",
    "    save_model_path = os.path.join(saved_model_dir, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Save the models state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models state dict\n",
    "print(f\"Saving model to: {save_model_path}\")\n",
    "torch.save(obj=model.state_dict(), # only saving the state_dict() only saves the learned parameters\n",
    "           f=save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "#######\n",
    "MODEL_NAME = \"unet_model_2classes_dataaugmentation_nonormalization_1e-06_30_1.pth\" # ---------> ADJUSTABLE!\n",
    "#######\n",
    "save_model_path = os.path.join(saved_model_dir, MODEL_NAME)\n",
    "\n",
    "# Create a new instance of the model (same class as our saved state_dict())\n",
    "loaded_model = model_utils.model_0.to(device)\n",
    "\n",
    "# Load in the saved state_dict()\n",
    "loaded_model.load_state_dict(torch.load(f=save_model_path, weights_only=True))\n",
    "\n",
    "# Send model to GPU\n",
    "loaded_model = loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ty97rk8oAxoA"
   },
   "source": [
    "## 6. Evaluate trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions for the entire test data set with the trained model and display the results in a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Confusion Matrix, Accuracies and F1-Scores\n",
    "Confusion Matrix for entire test data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for entire test data set\n",
    "evaluation_utils.evaluate_model_with_testdata(loaded_model, test_loader, accuracy_fn, configs_sc.HYPERPARAMETERS[\"num_classes\"], device, F1_analysis = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix, Accuracies and F1-Scores for a part of the test data set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for a part of the test data set\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# use only __ patch(es) of the test data set\n",
    "subset_indices = range(100)  # indices of sample test data set\n",
    "subset_test_data = Subset(test_loader.dataset, subset_indices)\n",
    "\n",
    "\n",
    "# create subset of test_loader\n",
    "subset_test_loader = DataLoader(subset_test_data, batch_size=test_loader.batch_size, shuffle=False)\n",
    "\n",
    "evaluation_utils.evaluate_model_with_testdata(\n",
    "    loaded_model, subset_test_loader, accuracy_fn, \n",
    "    configs_sc.HYPERPARAMETERS[\"num_classes\"], device, \n",
    "    F1_analysis = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zPwo5z1GxYA"
   },
   "source": [
    "### 6.2 Visual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Choose single patch by section and id\n",
    "SECTION = \"A04\" # -------------------->> ADJUSTABLE\n",
    "TEST_PATCH_ID = 207 # -------------------->> ADJUSTABLE\n",
    "#####################\n",
    "# 1432\n",
    "\n",
    "# Name of chosen patch\n",
    "test_patch_name = f\"{SECTION}_patch_{TEST_PATCH_ID}.npy\"\n",
    "\n",
    "visualization_utils.visualize_prediction(test_patch_name, test_loader, loaded_model, device, reversed_codes, configs_sc.HYPERPARAMETERS[\"custom_colors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3aTlcGv09d_"
   },
   "source": [
    "## Citing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hu7b1o7d1E_q"
   },
   "outputs": [],
   "source": [
    "# @misc{Iakubovskii:2019,\n",
    "#   Author = {Pavel Iakubovskii},\n",
    "#   Title = {Segmentation Models Pytorch},\n",
    "#   Year = {2019},\n",
    "#   Publisher = {GitHub},\n",
    "#   Journal = {GitHub repository},\n",
    "#   Howpublished = {\\url{https://github.com/qubvel/segmentation_models.pytorch}}\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0babcbba5b3d4151b15c00838a29ac33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b4bdb6ff45b430593277fa37e4d35ff",
       "IPY_MODEL_8e37aa7beecc4533a0cfb52ff1c88fc6",
       "IPY_MODEL_aaf88acb439641638112b4703c935672"
      ],
      "layout": "IPY_MODEL_abde49efc7d0493ba9aea25ca4c60050"
     }
    },
    "29589acaa6bc405cb6e040dc3f7ea2fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ff2f7585bec48a485704ecc8f2be347": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76cd84f3409843ee87769dc0aa3b52ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b4bdb6ff45b430593277fa37e4d35ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccda5c70ea8e4545a6ad9dbec748c27b",
      "placeholder": "â",
      "style": "IPY_MODEL_9bbb8694f72242588ea53dbe318c6ce7",
      "value": "ââ0%"
     }
    },
    "8e37aa7beecc4533a0cfb52ff1c88fc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ff2f7585bec48a485704ecc8f2be347",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_29589acaa6bc405cb6e040dc3f7ea2fa",
      "value": 0
     }
    },
    "9bbb8694f72242588ea53dbe318c6ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaf88acb439641638112b4703c935672": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76cd84f3409843ee87769dc0aa3b52ed",
      "placeholder": "â",
      "style": "IPY_MODEL_c85b6558ac9140a9895b4d97f2285472",
      "value": "â0/30â[23:40&lt;?,â?it/s]"
     }
    },
    "abde49efc7d0493ba9aea25ca4c60050": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c85b6558ac9140a9895b4d97f2285472": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ccda5c70ea8e4545a6ad9dbec748c27b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
